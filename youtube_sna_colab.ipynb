{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube SNA Scraper - Clean Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-api-python-client -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from googleapiclient.discovery import build\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'ISI_API_KEY'\n",
    "video_id = '3FwSeBfl61g'\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(video_id):\n",
    "    edges = []\n",
    "    request = youtube.commentThreads().list(part=\"snippet\", videoId=video_id, maxResults=100, textFormat=\"plainText\")\n",
    "    \n",
    "    page = 1\n",
    "    while request:\n",
    "        response = request.execute()\n",
    "        for item in response.get('items', []):\n",
    "            top = item['snippet']['topLevelComment']['snippet']\n",
    "            parent = top['authorDisplayName'].replace('@', '')\n",
    "            parent_id = item['snippet']['topLevelComment']['id']\n",
    "            reply_count = item['snippet'].get('totalReplyCount', 0)\n",
    "            \n",
    "            # Mentions in top comment\n",
    "            for m in re.findall(r'@([\\w.-]+)', top['textDisplay']):\n",
    "                edges.append({'Source': parent, 'Target': m.replace('@', '')})\n",
    "            \n",
    "            # All replies\n",
    "            if reply_count > 0:\n",
    "                try:\n",
    "                    rq = youtube.comments().list(part=\"snippet\", parentId=parent_id, maxResults=100, textFormat=\"plainText\")\n",
    "                    while rq:\n",
    "                        rr = rq.execute()\n",
    "                        for r in rr.get('items', []):\n",
    "                            rs = r['snippet']\n",
    "                            replier = rs['authorDisplayName'].replace('@', '')\n",
    "                            edges.append({'Source': replier, 'Target': parent})\n",
    "                            for m in re.findall(r'@([\\w.-]+)', rs['textDisplay']):\n",
    "                                edges.append({'Source': replier, 'Target': m.replace('@', '')})\n",
    "                        rq = youtube.comments().list(part=\"snippet\", parentId=parent_id, maxResults=100, textFormat=\"plainText\", pageToken=rr['nextPageToken']) if 'nextPageToken' in rr else None\n",
    "                except: pass\n",
    "        \n",
    "        print(f\"Page {page}: {len(edges)} edges\")\n",
    "        page += 1\n",
    "        request = youtube.commentThreads().list(part=\"snippet\", videoId=video_id, maxResults=100, textFormat=\"plainText\", pageToken=response['nextPageToken']) if 'nextPageToken' in response else None\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = scrape(video_id)\n",
    "print(f\"Total raw edges: {len(edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edges).drop_duplicates()\n",
    "print(f\"Unique edges: {len(df)}\")\n",
    "\n",
    "# Top targets\n",
    "print(\"\\nTop 15 Targets (paling banyak dibalas):\")\n",
    "print(df['Target'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df.to_csv('gephi_network.csv', index=False)\n",
    "files.download('gephi_network.csv')\n",
    "print('DONE - gephi_network.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
